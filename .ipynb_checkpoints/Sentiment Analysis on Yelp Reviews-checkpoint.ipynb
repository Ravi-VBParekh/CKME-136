{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn is used to perform sentiment analysis on Yelp Reviews. The Dataset is the Yelp Reviews on local businesses from the city of Markham.\n",
    "    ## SELECT review.text, review.stars FROM review JOIN business ON review.business_id = business.id WHERE business.city = 'Markham';\n",
    "    ## Export the Resultset to an external excel spreadsheet file. The saved file is of .XML format.\n",
    "    ## Save the Excel XML file to an .xlsx file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Markham = pd.read_excel('Markham.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataframe Markham has following columns - text and stars. For the sentiment analysis purpose our focus will be on these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like Dave, I've taken my Corolla here a few ti...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I started coming here because of my service ad...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The receptionists are not helpful.  I went the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've taken my Corolla here a few times for rep...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experienced a body ecu failure in my 6 month o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  Like Dave, I've taken my Corolla here a few ti...      2\n",
       "1  I started coming here because of my service ad...      5\n",
       "2  The receptionists are not helpful.  I went the...      1\n",
       "3  I've taken my Corolla here a few times for rep...      2\n",
       "4  Experienced a body ecu failure in my 6 month o...      5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     33923\n",
       "stars    33923\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markham.count() # number of rows before rows with missing values deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, we will clean up the dataframe and drop any rows with missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Markham.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     33923\n",
       "stars    33923\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markham.count() # number of rows after rows with missing values deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Problem\n",
    "## Next, reviews with stars = 3 are assumed to be neutral and removed from the dataframe.\n",
    "## A new column 'Sentiment' is created that will serve as target for our model, where any review text with stars more than 3 will be encoded as a 1, indicating a positive sentiment for the business. On the other hand, review text with stars less than 3 will be encoded as a 0, indicating a negative sentiment for the business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like Dave, I've taken my Corolla here a few ti...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I started coming here because of my service ad...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The receptionists are not helpful.  I went the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've taken my Corolla here a few times for rep...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experienced a body ecu failure in my 6 month o...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have owned nothing but Toyota Corolla's sinc...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mark is the guy you want to see in service. Go...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is usually where I go to get my vehicle s...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.5 stars  Brought my car in because it had a ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A regular 45min oil change was what I came for...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  Sentiment\n",
       "0  Like Dave, I've taken my Corolla here a few ti...      2          0\n",
       "1  I started coming here because of my service ad...      5          1\n",
       "2  The receptionists are not helpful.  I went the...      1          0\n",
       "3  I've taken my Corolla here a few times for rep...      2          0\n",
       "4  Experienced a body ecu failure in my 6 month o...      5          1\n",
       "5  I have owned nothing but Toyota Corolla's sinc...      5          1\n",
       "6  Mark is the guy you want to see in service. Go...      5          1\n",
       "7  This is usually where I go to get my vehicle s...      4          1\n",
       "8  3.5 stars  Brought my car in because it had a ...      3          0\n",
       "9  A regular 45min oil change was what I came for...      2          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markham = Markham[Markham['stars'] != 3]\n",
    "Markham['Sentiment'] = np.where(Markham['stars'] > 3, 1, 0)\n",
    "Markham.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance\n",
    "    ## It is evident from the mean of the Sentiment column and from the count of number of rows for each class, that we have imbalanced classes i.e. most reviews are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16471\n",
       "0     6610\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markham['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7136172609505654"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markham['Sentiment'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Split of the data into training and test sets using the text and sentiment columns.\n",
    "    ## Stratified sampling is evident from the mean and from the count of number of rows for each class in the y_train and y_test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Markham['text'], \n",
    "                                                    Markham['Sentiment'], \n",
    "                                                    test_size = 0.1,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry:\n",
      "\n",
      " Worst service ever...we got together with four families near Chinese New Year and safe to say we're never coming back. The waitress was extremely rude, coughed on her hands and continued setting up tables, without washing her hands. So we politely brought this to the manager. Turns out he didnt even say sorry, although he was not rude. He just had nothing to say. What kind of management is that? The worst thing is that the entire staff up front started talking about us behind our backs. They were mocking us and shot stares at our table all night. They were cursing at us, saying how we had Alzheimer's because we had elderly people, and also said we had menopause to our ladies. Absolutely horrible and unacceptable. We didn't even get an apology all night. As they (the staff) were sitting around for dinner, they continued gossiping with other staff. They intentionally spoke up so we would hear, bullying us not thinking we would react to it since we're not an aggressive group.  14 of us walked out the door unhappy that evening. Three of the families came from overseas and it gave Canadians a bad image. Shame on them, it's unfortunate they had to go through this. They had never experienced such bad service elsewhere, and neither did my family.  Perhaps they are still surviving because it's located in the busy Peach tree plaza, their food was ok, and the price is decent. If their service doesn't change, these factors won't make a difference. Good luck, and thanks for nothing on behalf of the 14 of us.\n",
      "\n",
      "\n",
      "X_train shape:  (20772,)\n",
      "\n",
      "\n",
      "X_test first entry:\n",
      "\n",
      " A snowy Saturday night in April!  Ordered naengmyun + galbi and jangjorim beef flank bibimbap The slushy broth is refreshing with a touch spicy kick to it. Nice chew to the noodles in a flavourful icy broth. The galbi had a nice amount of fat to it - delicious! The scissors make cutting through them like a breeze. Will definitely order it again! Bibimbap was a generous serving. Assortment of side dishes - really liked the eggplant and the radishes.  Price seems comparable to the other Korean restaurants in the area. There was a small lineup - came at 6:30pm hoping to beat the rush. Moment we came, a nice lady waiting in line told us we had to go to the front for a number.  25 minutes wait then we were seated. Pretty quick turnaround.  They give each person a piece of candy to end off the dinner.\n",
      "\n",
      "\n",
      "X_test shape:  (2309,)\n",
      "\n",
      "\n",
      "y_train counts:\n",
      "\n",
      " 1    14826\n",
      "0     5946\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "\n",
      "y_train mean:\n",
      "\n",
      " 0.7137492778740613\n",
      "\n",
      "\n",
      "y_test counts:\n",
      "\n",
      " 1    1645\n",
      "0     664\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "\n",
      "y_test mean:\n",
      "\n",
      " 0.7137492778740613\n"
     ]
    }
   ],
   "source": [
    "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)\n",
    "print('\\n\\nX_test first entry:\\n\\n', X_test.iloc[0])\n",
    "print('\\n\\nX_test shape: ', X_test.shape)\n",
    "print('\\n\\ny_train counts:\\n\\n', y_train.value_counts())\n",
    "print('\\n\\ny_train mean:\\n\\n', y_train.mean())\n",
    "print('\\n\\ny_test counts:\\n\\n', y_test.value_counts())\n",
    "print('\\n\\ny_test mean:\\n\\n', y_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Approach 1 : CountVectorizer (bag-of-words)\n",
    "    # X_train has a series of over 17,000 review text. These texts are converted into a matrix of token counts using CountVectorizer. CountVectorizer implements the bag-of-words approach which counts how often each word occurs in each review text.\n",
    "    # First, the CountVectorizer is fit to the training data. This tokenizes each text by finding all sequences of characters of at least two letters or numbers separated by word boundaries. It also converts the given text to lowercase and builds a vocabulary using these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english').fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The vocabulary is built on any tokens that occurred in the training data. Every 500th feature is extracted below and words with numbers as well as misspellings are observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '380',\n",
       " 'acai',\n",
       " 'alaska',\n",
       " 'approve',\n",
       " 'awestruck',\n",
       " 'beetle',\n",
       " 'blues',\n",
       " 'broke',\n",
       " 'campbell',\n",
       " 'chan',\n",
       " 'cinnamony',\n",
       " 'communicating',\n",
       " 'coors',\n",
       " 'crêpes',\n",
       " 'deems',\n",
       " 'diiiiieeee',\n",
       " 'doom',\n",
       " 'edamame',\n",
       " 'erupted',\n",
       " 'fades',\n",
       " 'fizz',\n",
       " 'freeboard',\n",
       " 'genes',\n",
       " 'gravitated',\n",
       " 'happened',\n",
       " 'holli',\n",
       " 'illustrates',\n",
       " 'instantly',\n",
       " 'jetta',\n",
       " 'kipz',\n",
       " 'leaveeeeeee',\n",
       " 'lord',\n",
       " 'marche',\n",
       " 'messing',\n",
       " 'monotone',\n",
       " 'neared',\n",
       " 'o5j4qjld9a0x3w6hepgdjg',\n",
       " 'ornaments',\n",
       " 'parchment',\n",
       " 'pharmacies',\n",
       " 'pomeranian',\n",
       " 'prison',\n",
       " 'quicky',\n",
       " 'reeeaaalllly',\n",
       " 'restarting',\n",
       " 'roux',\n",
       " 'sceptical',\n",
       " 'shaker',\n",
       " 'sincerely',\n",
       " 'soem',\n",
       " 'squatting',\n",
       " 'stubborn',\n",
       " 'swiss',\n",
       " 'tendou',\n",
       " 'tofufa',\n",
       " 'trusting',\n",
       " 'unlicensed',\n",
       " 'vert',\n",
       " 'wednesdays',\n",
       " 'wowza',\n",
       " '不過我覺得落粉炸反而比較好吃一點']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It could be seen from the length of the vocabulary that there are 28,886 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30867"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The transform method transforms the text in X_train to a document term matrix generating the bag-of-word representation of X_train where each row corresponds to a review text and each column a word from the training vocabulary vect.\n",
    "    \n",
    "### This representation is stored in a SciPy sparse matrix. The entries in this matrix are the number of times each word appears in each document. Because the number of words in the training vocabulary is much larger than the number of words that might appear in a single review text, most entries of this matrix are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20772x31170 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1692357 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.844044439692\n",
      "F1 score:  0.881476347254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print ('F1 score: ', f1_score(y_test, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 fold Cross - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.835473533412\n",
      "F1 score:  0.869373077423\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn import model_selection\n",
    "model = naive_bayes.MultinomialNB()\n",
    "\n",
    "predictions = model_selection.cross_val_predict(model, vect.transform(Markham['text']), Markham['Sentiment'], cv=5)\n",
    "print('AUC: ', roc_auc_score(Markham['Sentiment'], predictions))\n",
    "print ('F1 score: ', f1_score(Markham['Sentiment'], predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-f0d306d14cbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "predictions.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel = 'linear', C=0.1, class_weight = 'balanced')\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.917028390818\n",
      "F1 score:  0.925489516548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print ('F1 score: ', f1_score(y_test, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier\n",
    "    ### Feature matrix X_train_vectorized is used to train Logistic Regression model which works well for high dimensional sparse data [Komarek, Paul, and Andrew W. Moore. \"Fast Robust Logistic Regression for Large Sparse Datasets with Binary Outputs.\" In AISTATS. 2003.]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First the X_test is transformed using the vectorizer that was fitted to the training data. Followed by the use of X_test to make predictions and compute the area under the curve score. Note that any words in X_test that didn't appear in X_train are ignored. AUC score of about 0.912 is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.912116244943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the 20 smallest and 20 largest coefficients from the model.\n",
    "    # The model has connected words like 'worst' 'terrible' 'mediocre' 'bland' 'horrible' 'worse' 'overpriced' 'poor' 'disappointing' 'undercooked' 'disappointment' 'sick' 'rude' 'zero' 'ridiculous' 'wouldn' 'dirty' 'poisoning' 'cockroach' 'minimum' to negative reviews and\n",
    "    # words like 'excellent' 'amazing' 'delicious' 'complaints' 'yummy' 'tasty' 'reasonable' 'satisfied' 'love' 'highly' 'best' 'solid' 'great' 'favourites' 'reasonably' 'glad' 'superb' 'favourite' 'complaint' 'notch' to positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['worst' 'terrible' 'mediocre' 'bland' 'horrible' 'worse' 'overpriced'\n",
      " 'poor' 'disappointing' 'undercooked' 'disappointment' 'sick' 'rude' 'zero'\n",
      " 'ridiculous' 'wouldn' 'dirty' 'poisoning' 'cockroach' 'minimum']\n",
      "\n",
      "Largest Coefs: \n",
      "['excellent' 'amazing' 'delicious' 'complaints' 'yummy' 'tasty'\n",
      " 'reasonable' 'satisfied' 'love' 'highly' 'best' 'solid' 'great'\n",
      " 'favourites' 'reasonably' 'glad' 'superb' 'favourite' 'complaint' 'notch']\n"
     ]
    }
   ],
   "source": [
    "# the feature names are taken into the numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# The 20 largest coefficients are being indexed using [:-21:-1] so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-21:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Approach 2 : Rescale features using Tf–idf (Term frequency-inverse document frequency)\n",
    "\n",
    "#### Tf–idf weight features based on how important they are to a text. High weight is given to features that appear frequently within a particular text, but appear rarely in the corpus. Features with low tf–idf are either commonly used across all texts or rarely used and only occur in long texts.\n",
    "\n",
    "#### Fit tf–idf vectorizer to the training data.\n",
    "\n",
    "#### Number of features can be reduced substantially by specifying a minimum number of documents (min_df) in which a word needs to appear to become part of the vocabulary. As a result some words that might appear in only a few text and are unlikely to be useful predictors are removed. For example, with min_df = 5, any words that appeared in fewer than five documents will be removed from the vocabulary.\n",
    "\n",
    "\n",
    "#### With min_df=1 TfidfVectorizer returns the same number of features as CountVectorizer. However, with AUC 0.884 there seemed to be no improvemnent in model performance as compared to bag-of-words approach. As seen from the results below varying min_df value does reduced the number of features subtantially but it didn't helped in improving the model performance.\n",
    "\n",
    "    min_df = 1; no. of features = 28886; AUC = 0.884\n",
    "    min_df = 2; no. features = 16616; AUC = 0.885\n",
    "    min_df = 3; no. of features = 13061; AUC = 0.886\n",
    "    min_df = 4; no. of features = 11136; AUC = 0.885\n",
    "    min_df = 5; no. of features = 9871; AUC = 0.885\n",
    "    min_df = 6; no. of features = 8940; AUC = 0.886\n",
    "    min_df = 7; no. of features = 8214; AUC = 0.886\n",
    "    min_df = 8; no. of features = 7626; AUC = 0.887\n",
    "    min_df = 9; no. of features = 7128; AUC = 0.887\n",
    "    min_df = 10; no. of features = 6745; AUC = 0.887\n",
    "    min_df = 50; no. of features = 2619; AUC = 0.889\n",
    "    min_df = 100; no. of features = 1705; AUC = 0.888\n",
    "    min_df = 200; no. of features = 1039; AUC = 0.885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13061"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=3).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, transform the training data, fit logistic regression model, make predictions on the transform test data, and compute the AUC score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.886065368546\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features with the smallest tf–idf either appear commonly across all reviews or only rarely in very long reviews. Whereas features with the largest tf–idf appear frequently in a review, but rarely across all reviews. \n",
    "\n",
    "### Extracting the smallest and largest coefficients from the model results in the list of words connected to negative and positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['artfully' 'registering' 'guidelines' 'jackfruit' 'rectangles' 'clip'\n",
      " 'freed' 'forbid' 'awakens' 'belonged' 'gouge' 'arch' 'releases'\n",
      " 'awkwardness' 'idiotic' 'lighten' 'admitting' 'acidity' 'shuts' 'behold']\n",
      "\n",
      "Largest tfidf: \n",
      "['ann' 'ale' 'tongue' 'veg' 'kabob' 'burger' 'fab' 'yes' 'bagels' 'afghani'\n",
      " 'stinky' 'ladies' 'awful' 'yoghurt' 'teacher' 'macaroon' 'peri' 'gelato'\n",
      " 'popice' 'cheeseburgers']\n"
     ]
    }
   ],
   "source": [
    "# the feature names are taken into the numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "# The 20 largest coefficients are being indexed using [:-21:-1] so the list returned is in order of largest to smallest\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:20]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-21:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['not' 'worst' 'terrible' 'bland' 'mediocre' 'horrible' 'no' 'disappointed'\n",
      " 'rude' 'poor' 'disappointing' 'nothing' 'wasn' 'okay' 'bad' 'overpriced'\n",
      " 'worse' 'better' 'don' 'wouldn']\n",
      "\n",
      "Largest Coefs: \n",
      "['great' 'delicious' 'good' 'amazing' 'love' 'best' 'excellent'\n",
      " 'definitely' 'friendly' 'tasty' 'nice' 'perfect' 'and' 'try' 'always'\n",
      " 'favourite' 'fresh' 'reasonable' 'quick' 'awesome']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-21:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem with bag-of-words approach is that word order is disregarded. So, the model sees both the sentences below as negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by bag-of-words model\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Approach 3 : n-grams\n",
    "### Add some meaning by adding sequences of word features known as n-grams. For example, bigrams, which count pairs of adjacent words, could give features such as 'is working' versus 'not working'. And trigrams, which give triplets of adjacent words, could give features such as 'not an issue'.\n",
    "\n",
    "### Create n-gram features by passing a tuple to the parameter ngram_range, where the values correspond to the minimum length and maximum lengths of sequences.\n",
    "### For example, if ngram_range=(1,2), CountVectorizer will create features using the individual words, as well as the bigrams. Although n-grams can be powerful in capturing meaning, longer sequences can cause an explosion of the number of features. \n",
    "\n",
    "### By adding bigrams, the number of features has increased to almost ________. AUC score improved to _____ after training logistic regression model with new features including bigrams &/or trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203834"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=3, ngram_range=(1,3)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.923306003708\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at what features our model connected with negative reviews, we can see that we now have bigrams such as no good and not happy, \n",
    "9:24\n",
    "while for positive reviews we have not bad and no problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['terrible' 'worst' 'horrible' 'bland' 'mediocre' 'poor' 'overpriced'\n",
      " 'disappointing' 'rude' 'worse' 'disappointed' 'wouldn' 'not' 'not worth'\n",
      " 'okay' 'definitely not' 'awful' 'wasn' 'dirty' 'bad']\n",
      "\n",
      "Largest Coefs: \n",
      "['delicious' 'amazing' 'excellent' 'great' 'love' 'best' 'not bad' 'tasty'\n",
      " 'better than' 'not too' 'good' 'definitely' 'yummy' 'fantastic' 'awesome'\n",
      " 'friendly' 'reasonable' 'nice' 'perfect' 'must']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:20]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-21:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we again try to predict not an issue, phone is working, and an issue, phone is not working, we can see that our newest model now correctly identifies them as positive and negative reviews respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are now correctly identified\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
